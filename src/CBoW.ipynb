{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "CBoW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F6LB7bDWswC"
      },
      "source": [
        "import preprocess\n",
        "import utils\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import pandas as pd\n",
        "import csv\n",
        "import pickle as pkl\n",
        "import random\n",
        "from sklearn.utils import gen_batches\n",
        "import numpy as np\n",
        "import scorer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-na_UThWswI"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etqqauwZWswJ"
      },
      "source": [
        "load_preprocessed_data = False\n",
        "\n",
        "if load_preprocessed_data:\n",
        "    path_to_data = 'data.pkl'\n",
        "    path_to_vocab_dict = 'vocab_dict.pkl'\n",
        "    \n",
        "    data = utils.load_preprocessed_data(path_to_data)\n",
        "    vocab_dict = utils.load_vocab_dict(path_to_vocab_dict)\n",
        "    (headlines_train, stances_train, bodies_train) = data['train']\n",
        "    (headlines_dev, stances_dev, bodies_dev) = data['dev']\n",
        "else:\n",
        "    train_stances_path = 'train_stances.csv'\n",
        "    train_bodies_path = 'train_bodies.csv'\n",
        "\n",
        "    stances_data =  pd.read_csv(train_stances_path)\n",
        "    bodies_data = pd.read_csv(train_bodies_path)\n",
        "\n",
        "    data = preprocess.extract_data(stances_data, bodies_data)\n",
        "    vocab_dict = data['dict']\n",
        "    (headlines_train, stances_train, bodies_train) = data['train']\n",
        "    (headlines_dev, stances_dev, bodies_dev) = data['dev']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jelnd8TKWswK"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fllH5Z8CWswL"
      },
      "source": [
        "is_cuda = True\n",
        "\n",
        "if is_cuda:\n",
        "    device = th.device('cuda:0')\n",
        "else:\n",
        "    device = th.device('cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJGDsfeMWswM"
      },
      "source": [
        "class CBOW_classifier(nn.Module):\n",
        "    def __init__(self, vocab_dict, embedding_dim, num_layers=0, hidden_dim=50, dropout=0.5):\n",
        "        super(CBOW_classifier, self).__init__()     \n",
        "        output_dim = 4\n",
        "        self.embedding = nn.Embedding(len(vocab_dict), embedding_dim, padding_idx=vocab_dict['<pad>'])\n",
        "        if num_layers > 0:\n",
        "            first_layer = nn.Sequential(nn.Linear(2*embedding_dim, hidden_dim),nn.ReLU())\n",
        "            hidden_layers = [nn.Sequential(nn.Linear(hidden_dim, hidden_dim),nn.ReLU()) for i in range(num_layers-1)]\n",
        "            self.out = nn.Sequential(nn.Dropout(dropout), first_layer, *hidden_layers, nn.Dropout(dropout), nn.Linear(hidden_dim, output_dim))\n",
        "        else:\n",
        "            self.out = nn.Sequential(nn.Dropout(dropout),nn.Linear(2*embedding_dim, output_dim))        \n",
        "        \n",
        "    def forward(self, headlines, bodies):\n",
        "        headlines_embedded = th.sum(self.embedding(headlines), axis=1)\n",
        "        bodies_embedded = th.sum(self.embedding(bodies), axis=1)\n",
        "        embeds = th.cat((headlines_embedded, bodies_embedded), 1)\n",
        "        out = self.out(embeds)\n",
        "        return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMS3yfArWswM"
      },
      "source": [
        "embedding_dim = 1000\n",
        "model = CBOW_classifier(vocab_dict, embedding_dim, num_layers=5, hidden_dim=150, dropout=0.5).to(device)\n",
        "lr = 0.001\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = th.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-m6NvtJWswN",
        "outputId": "0a032388-4ae6-4493-ea8b-66d76a1752c7"
      },
      "source": [
        "num_epochs = 80\n",
        "batch_size = 256\n",
        "num_samples = len(headlines_train)\n",
        "\n",
        "slices = list(gen_batches(num_samples, batch_size))\n",
        "dev_slices = list(gen_batches(len(headlines_dev), batch_size))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    for s in slices:\n",
        "\n",
        "        headlines_batch = headlines_train[s].to(device)\n",
        "        stances_batch = stances_train[s].to(device)\n",
        "        bodies_batch = bodies_train[s].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()  \n",
        "        pred_labels = model(headlines_batch, bodies_batch)\n",
        "        loss = loss_function(pred_labels, stances_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    accs = []\n",
        "    for s in dev_slices:   \n",
        "        acc = utils.compute_accuracy(\n",
        "            model, \n",
        "            headlines_dev[s].to(device), \n",
        "            stances_dev[s].to(device), \n",
        "            bodies_dev[s].to(device)\n",
        "        )\n",
        "        accs.append(acc)\n",
        "    acc = sum(accs) / len(accs)\n",
        "    \n",
        "    slices_rand = np.random.permutation(slices)\n",
        "    trainaccs = []\n",
        "    for i in range(6):\n",
        "        s = slices_rand[i]\n",
        "        trainaccs.append(utils.compute_accuracy(\n",
        "            model,\n",
        "            headlines_train[s].to(device),\n",
        "            stances_train[s].to(device),\n",
        "            bodies_train[s].to(device)\n",
        "        ))\n",
        "    trainacc = sum(trainaccs) / len(trainaccs)\n",
        "    \n",
        "    print('Epoch:', epoch, \"Accuracy: %f\" % acc, \"Train accuracy: %f\" % trainacc)\n",
        "    print('\\tLoss:', epoch_loss / len(slices))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Accuracy: 0.736736 Train accuracy: 0.749349\n",
            "\tLoss: 0.8071986095161195\n",
            "Epoch: 1 Accuracy: 0.809517 Train accuracy: 0.813151\n",
            "\tLoss: 0.6258081433120047\n",
            "Epoch: 2 Accuracy: 0.845259 Train accuracy: 0.854818\n",
            "\tLoss: 0.5031262808924268\n",
            "Epoch: 3 Accuracy: 0.863938 Train accuracy: 0.866536\n",
            "\tLoss: 0.40800694314537533\n",
            "Epoch: 4 Accuracy: 0.889453 Train accuracy: 0.908203\n",
            "\tLoss: 0.3466499261320776\n",
            "Epoch: 5 Accuracy: 0.902051 Train accuracy: 0.918620\n",
            "\tLoss: 0.2935646108950779\n",
            "Epoch: 6 Accuracy: 0.919922 Train accuracy: 0.936198\n",
            "\tLoss: 0.2563579182146461\n",
            "Epoch: 7 Accuracy: 0.921289 Train accuracy: 0.932943\n",
            "\tLoss: 0.23273842831610875\n",
            "Epoch: 8 Accuracy: 0.927148 Train accuracy: 0.945312\n",
            "\tLoss: 0.20390676915835423\n",
            "Epoch: 9 Accuracy: 0.926829 Train accuracy: 0.953125\n",
            "\tLoss: 0.1907242870278609\n",
            "Epoch: 10 Accuracy: 0.936621 Train accuracy: 0.970703\n",
            "\tLoss: 0.1741378073028888\n",
            "Epoch: 11 Accuracy: 0.938379 Train accuracy: 0.964844\n",
            "\tLoss: 0.15981585461242942\n",
            "Epoch: 12 Accuracy: 0.940501 Train accuracy: 0.974609\n",
            "\tLoss: 0.14557609503056593\n",
            "Epoch: 13 Accuracy: 0.945312 Train accuracy: 0.970052\n",
            "\tLoss: 0.13347856534324634\n",
            "Epoch: 14 Accuracy: 0.950000 Train accuracy: 0.979167\n",
            "\tLoss: 0.12652946545914479\n",
            "Epoch: 15 Accuracy: 0.947630 Train accuracy: 0.975260\n",
            "\tLoss: 0.12033746168491946\n",
            "Epoch: 16 Accuracy: 0.951563 Train accuracy: 0.973307\n",
            "\tLoss: 0.11413835940562236\n",
            "Epoch: 17 Accuracy: 0.954297 Train accuracy: 0.977865\n",
            "\tLoss: 0.10998539874555578\n",
            "Epoch: 18 Accuracy: 0.954297 Train accuracy: 0.977865\n",
            "\tLoss: 0.10362822450934701\n",
            "Epoch: 19 Accuracy: 0.958398 Train accuracy: 0.977214\n",
            "\tLoss: 0.09998010887888967\n",
            "Epoch: 20 Accuracy: 0.956055 Train accuracy: 0.972656\n",
            "\tLoss: 0.09463577099429195\n",
            "Epoch: 21 Accuracy: 0.960449 Train accuracy: 0.981120\n",
            "\tLoss: 0.0887740238504425\n",
            "Epoch: 22 Accuracy: 0.958301 Train accuracy: 0.980469\n",
            "\tLoss: 0.08649140827737417\n",
            "Epoch: 23 Accuracy: 0.959961 Train accuracy: 0.979167\n",
            "\tLoss: 0.08342676692802435\n",
            "Epoch: 24 Accuracy: 0.960840 Train accuracy: 0.988932\n",
            "\tLoss: 0.07463669762679725\n",
            "Epoch: 25 Accuracy: 0.961719 Train accuracy: 0.986328\n",
            "\tLoss: 0.07304995915864351\n",
            "Epoch: 26 Accuracy: 0.961719 Train accuracy: 0.988281\n",
            "\tLoss: 0.07026145152101045\n",
            "Epoch: 27 Accuracy: 0.961914 Train accuracy: 0.989583\n",
            "\tLoss: 0.0715355738600016\n",
            "Epoch: 28 Accuracy: 0.963477 Train accuracy: 0.991536\n",
            "\tLoss: 0.06640192230415952\n",
            "Epoch: 29 Accuracy: 0.964844 Train accuracy: 0.990885\n",
            "\tLoss: 0.06542106854334877\n",
            "Epoch: 30 Accuracy: 0.963965 Train accuracy: 0.986979\n",
            "\tLoss: 0.06359439233768803\n",
            "Epoch: 31 Accuracy: 0.964844 Train accuracy: 0.989583\n",
            "\tLoss: 0.0627856632623418\n",
            "Epoch: 32 Accuracy: 0.966309 Train accuracy: 0.988932\n",
            "\tLoss: 0.05932433154006862\n",
            "Epoch: 33 Accuracy: 0.966309 Train accuracy: 0.987630\n",
            "\tLoss: 0.055421359326903986\n",
            "Epoch: 34 Accuracy: 0.966309 Train accuracy: 0.988932\n",
            "\tLoss: 0.05422954838485665\n",
            "Epoch: 35 Accuracy: 0.969531 Train accuracy: 0.995443\n",
            "\tLoss: 0.05652475491489408\n",
            "Epoch: 36 Accuracy: 0.970508 Train accuracy: 0.988932\n",
            "\tLoss: 0.05353783799267143\n",
            "Epoch: 37 Accuracy: 0.969922 Train accuracy: 0.994141\n",
            "\tLoss: 0.04624516439511423\n",
            "Epoch: 38 Accuracy: 0.970801 Train accuracy: 0.992839\n",
            "\tLoss: 0.048809235580384164\n",
            "Epoch: 39 Accuracy: 0.970605 Train accuracy: 0.992839\n",
            "\tLoss: 0.04297569200429813\n",
            "Epoch: 40 Accuracy: 0.971094 Train accuracy: 0.994792\n",
            "\tLoss: 0.046888593070440375\n",
            "Epoch: 41 Accuracy: 0.971875 Train accuracy: 0.991536\n",
            "\tLoss: 0.0460600232012914\n",
            "Epoch: 42 Accuracy: 0.971191 Train accuracy: 0.994141\n",
            "\tLoss: 0.041808461067474385\n",
            "Epoch: 43 Accuracy: 0.970969 Train accuracy: 0.994792\n",
            "\tLoss: 0.04419654457693457\n",
            "Epoch: 44 Accuracy: 0.970188 Train accuracy: 0.994141\n",
            "\tLoss: 0.04074148042794839\n",
            "Epoch: 45 Accuracy: 0.967747 Train accuracy: 0.996094\n",
            "\tLoss: 0.04026111868761812\n",
            "Epoch: 46 Accuracy: 0.973340 Train accuracy: 0.994141\n",
            "\tLoss: 0.03866041221827933\n",
            "Epoch: 47 Accuracy: 0.976074 Train accuracy: 0.997396\n",
            "\tLoss: 0.039346884099312814\n",
            "Epoch: 48 Accuracy: 0.972656 Train accuracy: 0.992839\n",
            "\tLoss: 0.03710271581947347\n",
            "Epoch: 49 Accuracy: 0.973020 Train accuracy: 0.994792\n",
            "\tLoss: 0.03678226029636106\n",
            "Epoch: 50 Accuracy: 0.974707 Train accuracy: 0.998698\n",
            "\tLoss: 0.034912660853102344\n",
            "Epoch: 51 Accuracy: 0.972923 Train accuracy: 0.996745\n",
            "\tLoss: 0.03608471868210472\n",
            "Epoch: 52 Accuracy: 0.974707 Train accuracy: 0.996745\n",
            "\tLoss: 0.03307813692802362\n",
            "Epoch: 53 Accuracy: 0.974707 Train accuracy: 0.995443\n",
            "\tLoss: 0.033720071451252054\n",
            "Epoch: 54 Accuracy: 0.972825 Train accuracy: 0.996094\n",
            "\tLoss: 0.03296886175595336\n",
            "Epoch: 55 Accuracy: 0.975684 Train accuracy: 0.998047\n",
            "\tLoss: 0.033023681191399035\n",
            "Epoch: 56 Accuracy: 0.974121 Train accuracy: 0.994792\n",
            "\tLoss: 0.031154264685422386\n",
            "Epoch: 57 Accuracy: 0.975879 Train accuracy: 0.998047\n",
            "\tLoss: 0.033373275856175284\n",
            "Epoch: 58 Accuracy: 0.975879 Train accuracy: 0.994792\n",
            "\tLoss: 0.031214418433279253\n",
            "Epoch: 59 Accuracy: 0.976074 Train accuracy: 0.998047\n",
            "\tLoss: 0.029529327366524822\n",
            "Epoch: 60 Accuracy: 0.973340 Train accuracy: 0.996745\n",
            "\tLoss: 0.02633885120317506\n",
            "Epoch: 61 Accuracy: 0.977148 Train accuracy: 0.995443\n",
            "\tLoss: 0.02848522634599104\n",
            "Epoch: 62 Accuracy: 0.975098 Train accuracy: 0.995443\n",
            "\tLoss: 0.030558823127556107\n",
            "Epoch: 63 Accuracy: 0.973606 Train accuracy: 0.995443\n",
            "\tLoss: 0.029656652922005762\n",
            "Epoch: 64 Accuracy: 0.974121 Train accuracy: 0.994792\n",
            "\tLoss: 0.026749776679263183\n",
            "Epoch: 65 Accuracy: 0.975977 Train accuracy: 0.996745\n",
            "\tLoss: 0.024921977610099663\n",
            "Epoch: 66 Accuracy: 0.973020 Train accuracy: 0.996094\n",
            "\tLoss: 0.0257775961498546\n",
            "Epoch: 67 Accuracy: 0.973509 Train accuracy: 0.997396\n",
            "\tLoss: 0.02571421871065595\n",
            "Epoch: 68 Accuracy: 0.975266 Train accuracy: 0.998698\n",
            "\tLoss: 0.02432947503685989\n",
            "Epoch: 69 Accuracy: 0.976145 Train accuracy: 0.997396\n",
            "\tLoss: 0.023598647562217464\n",
            "Epoch: 70 Accuracy: 0.971751 Train accuracy: 0.996094\n",
            "\tLoss: 0.02690952123148062\n",
            "Epoch: 71 Accuracy: 0.974485 Train accuracy: 0.998698\n",
            "\tLoss: 0.02548812494253279\n",
            "Epoch: 72 Accuracy: 0.973216 Train accuracy: 0.995443\n",
            "\tLoss: 0.020412936736977878\n",
            "Epoch: 73 Accuracy: 0.975852 Train accuracy: 0.998047\n",
            "\tLoss: 0.02324890018429881\n",
            "Epoch: 74 Accuracy: 0.972044 Train accuracy: 0.995443\n",
            "\tLoss: 0.0218847864014687\n",
            "Epoch: 75 Accuracy: 0.973509 Train accuracy: 0.996745\n",
            "\tLoss: 0.023550224908981912\n",
            "Epoch: 76 Accuracy: 0.975364 Train accuracy: 0.999349\n",
            "\tLoss: 0.020052964200299443\n",
            "Epoch: 77 Accuracy: 0.974095 Train accuracy: 0.998698\n",
            "\tLoss: 0.02030819064481881\n",
            "Epoch: 78 Accuracy: 0.975950 Train accuracy: 0.998047\n",
            "\tLoss: 0.022819547486865217\n",
            "Epoch: 79 Accuracy: 0.975755 Train accuracy: 0.997396\n",
            "\tLoss: 0.02210557242710096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huSyNhXOWswO"
      },
      "source": [
        "# Saving data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vPh8SJTWswO"
      },
      "source": [
        "save_data = True\n",
        "\n",
        "if save_data:\n",
        "    vocab_dict_path = 'vocab_dict_new.pkl'\n",
        "    model_weights_path = 'cbow_09757.pth'\n",
        "    data_path = 'data_new.pkl'\n",
        "    \n",
        "    # utils.save_vocab_dict(vocab_dict_path, vocab_dict)\n",
        "    utils.save_model_weights(model_weights_path, model)\n",
        "    # utils.save_preprocessed_data(data_path, {\n",
        "    #     'train': (headlines_train, stances_train, bodies_train),\n",
        "    #     'dev': (headlines_dev, stances_dev, bodies_dev)\n",
        "    # })"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iac78UfYWswO"
      },
      "source": [
        "# Loading model\n",
        "\n",
        "The following code loads the model. There is no need to run this part if the model was trained in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STaqRN6gWswQ"
      },
      "source": [
        "load_model = False\n",
        "\n",
        "if load_model:\n",
        "    path_to_vocab_dict = 'vocab_dict.pkl'\n",
        "    path_to_model_weights = 'cbow_09502.pth'\n",
        "\n",
        "    embedding_dim = 1000\n",
        "    model = CBOW_classifier(vocab_dict, embedding_dim, num_layers=1, dropout=0.1)\n",
        "\n",
        "    vocab_dict = utils.load_vocab_dict(path_to_vocab_dict)\n",
        "    model = utils.load_model_weights(model, path_to_model_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PHBPqVZWswQ"
      },
      "source": [
        "# Evaluating the model\n",
        "\n",
        "the following code loads test data, runs them through the model, and saves them to a CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_YsBm2yWswQ"
      },
      "source": [
        "bodies_data = pd.read_csv('competition_test_bodies.csv')\n",
        "stances_data =  pd.read_csv('competition_test_stances.csv')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EajqcT_iWswR"
      },
      "source": [
        "headlines, _, bodies = preprocess.transform_data(stances_data, bodies_data, vocab_dict)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOFla4DEWswR"
      },
      "source": [
        "slices = list(gen_batches(len(headlines), 200))\n",
        "predictions = []\n",
        "model.eval()\n",
        "for s in slices:   \n",
        "    with th.no_grad():\n",
        "        outputs = model.forward(\n",
        "            headlines[s].to(device), \n",
        "            bodies[s].to(device)\n",
        "        ).argmax(axis=1)\n",
        "\n",
        "        predictions += outputs.tolist()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3DZn4QYWswS"
      },
      "source": [
        "predictions_words = preprocess.transform_back_stances(predictions)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3tdvEX6WswS"
      },
      "source": [
        "prediction_data = list(zip(\n",
        "    stances_data['Headline'].values.tolist(), \n",
        "    stances_data['Body ID'].values.tolist(), \n",
        "    predictions_words\n",
        "))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX9_vi2ZWswS"
      },
      "source": [
        "with open('predictions.csv', 'w') as pred_file:\n",
        "    writer = csv.writer(pred_file)\n",
        "    writer.writerow(['Headline', 'Body ID', 'Stance'])\n",
        "    writer.writerows(prediction_data)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c1DqLb6RkJn",
        "outputId": "319edb01-3ae4-4e5c-d873-8b35d05b6995"
      },
      "source": [
        "gold_filename = 'competition_test_stances.csv'\n",
        "\n",
        "gold_labels = scorer.load_dataset(gold_filename)\n",
        "test_labels = scorer.load_dataset('predictions.csv')\n",
        "\n",
        "test_score, cm = scorer.score_submission(gold_labels, test_labels)\n",
        "null_score, max_score = scorer.score_defaults(gold_labels)\n",
        "scorer.print_confusion_matrix(cm)\n",
        "print(scorer.SCORE_REPORT.format(max_score, null_score, test_score))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX:\n",
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |   1104    |    13     |    722    |    64     |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    422    |     8     |    221    |    46     |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    991    |    19     |   3258    |    196    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |   4893    |    67     |   8688    |   4701    |\n",
            "-------------------------------------------------------------\n",
            "ACCURACY: 0.357\n",
            "\n",
            "MAX  - the best possible score (100% accuracy)\n",
            "NULL - score as if all predicted stances were unrelated\n",
            "TEST - score based on the provided predictions\n",
            "\n",
            "||    MAX    ||    NULL   ||    TEST   ||\n",
            "|| 11651.25  ||  4587.25  ||  6142.25  ||\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m_2xEGqnuXV",
        "outputId": "1fb7c246-5cf0-4d9a-f1af-9a8be4be14d6"
      },
      "source": [
        "len(vocab_dict)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20295"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efOnp3sHTPrK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}